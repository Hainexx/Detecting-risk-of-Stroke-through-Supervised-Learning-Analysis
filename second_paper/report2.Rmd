---
title: "Second Paper"
author: "Ordinary Leading Students"
date: "6/02/2021"
output:
  pdf_document: default
  html_document: default
  word_document: default
header-includes:
- \usepackage{subfig}
- \usepackage{bbm}
urlcolor: blue
---

```{r, include=FALSE, message=FALSE}
# Loading libraries
library(ggplot2)
library(grid)
library(gridExtra)
library(cluster)
library(readr)
library(corrplot) 
library(factoextra)
library(png)
```


\begin{abstract}
In this paper we are going to perform a cluster analysis on a dataset used for a 
market basket analysis. Our goal is to find unknown subgroups in the dataset.

\end{abstract}

\section{Data}
We will now load and present our dataset (that can be retrieved at the following [link](https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python)). 

```{r, message=FALSE}
# Set the working directory and load the dataset
setwd(dirname(rstudioapi::getSourceEditorContext()$path))

malldt<- read_csv("Mall_Customers.csv")

# Summary of the dataset without the id column
summary(malldt[-1])
```

\section{Data Cleaning}

We removed the **CustomerID** variable and converted the **Gender** variable in factor.

```{r}
malldt$CustomerID <- NULL
malldt$Gender <- as.factor(malldt$Gender)
```

\newpage

\section{Data Visualization}


```{r}
# Gender Boxplots

par(mfrow=c(1,2))
boxplot(`Annual Income (k$)`~Gender,data=malldt, col="#2D708EFF")
boxplot(`Spending Score (1-100)`~Gender,data=malldt, col="darkgoldenrod2")

```

As we can see there are no meaningful differences between the genders group.

\newpage

```{r}
# Age Boxplots

# Create age groups
labs <- c(paste(seq(15, 70, by = 20), seq(15 + 20 - 1, 80, by = 20), 
                sep = "-"))

malldt$AgeGroup <- cut(malldt$Age, breaks = c(seq(15, 70, by = 20), Inf), 
                       labels = labs, right = FALSE)

par(mfrow=c(1,2))
boxplot(`Annual Income (k$)`~AgeGroup,data=malldt, col="#FF99CC")
boxplot(`Spending Score (1-100)`~AgeGroup,data=malldt, col="#33CC66")
```

The only interesting information we can retrieve from the plots is that the youngest (age between 15 and 34) have an **higher spending score**, but not other significant information stands out.

```{r, include=FALSE}
# Remove the age groups
malldt$AgeGroup <- NULL
```

\newpage

\section{Dendograms}

Now we start finding subgroups using clustering techniques.

First we used the **Gower's distance** to build dendrograms with different methods. \
This distance can be used to measure how different two records are and it 
is always a number between 0 (identical) and 1 (maximally dissimilar). It
is computed as the average of partial dissimilarities across individuals.

```{r}
# Gower distance works for mixed variables
malldt.dist<-daisy(malldt,metric="gower")

# Dendrograms
malldt.hc.com<-hclust(malldt.dist,method="complete") 
plot(malldt.hc.com, main="Complete Method") 
rect.hclust(malldt.hc.com,k=3,border=c("red","green","blue")) 

malldt.hc.sin<-hclust(malldt.dist,method="single") 
plot(malldt.hc.sin, main="Single Method") 
rect.hclust(malldt.hc.sin,k=3,border=c("red","green","blue")) 

malldt.hc.ave<-hclust(malldt.dist,method="average") 
plot(malldt.hc.ave, main="Average Method") 
rect.hclust(malldt.hc.ave,k=3,border=c("red","green","blue")) 

malldt.hc.cen<-hclust(malldt.dist,method="centroid") 
plot(malldt.hc.cen, main="Centroid Method") 
rect.hclust(malldt.hc.cen,k=3,border=c("red","green","blue")) 

malldt.hc.ward<-hclust(malldt.dist,method="ward.D2") 
plot(malldt.hc.ward, main="Ward Method") 
rect.hclust(malldt.hc.ward,k=8,border=c("red","green","blue"))

```

\subsection{Ward Method}

The **Ward Method** is clearly the best one, it detects 8 groups in our data.
Let us count how many observations there are in each group.

```{r}
# Allocate obs into 8 groups
malldt.groups.ward<-cutree(malldt.hc.ward,k=8) 
malldt.groups.ward

# Number of observations in each group
table(malldt.groups.ward)
```


Then for every group we compute the mean value of each variable. 


```{r}
clusterdata.mean<-function(data,groups){
  aggregate(data,list(groups),function(x)mean(as.numeric(x)))
}

clusterdata.mean(malldt,malldt.groups.ward)
```

From this table we can see that there are many groups that are quite similar to each other, but there are also some interesting differences:
\begin{itemize}
\item \textbf{Gender}: the eight groups are evenly split between ones containing more males and one containing more females. 
\item \textbf{Age}: group 4 and group 5 stand out from the rest, they contain people who tend to be older. Between groups 4 and 5 the only noticeable difference is the **gender**, whereas the other variables are more or less in the same range. \
\item \textbf{Annual income}: the groups could be divided in two. Groups 1 to 5 have annual incomes between 40.000\$ and 60.000\$, then there is quite a big jump in groups 6 to 8, which all have annual incomes above 80.000\$. 
\item \textbf{Spending score}: the spending score varies quite a lot among the groups, even between groups that are similar in other aspects. For example, groups 7 and 8 are quite close in age and annual income, but males appear to have a much higher spending score than females. 

We have obtained a good result, but it can still be improved, since there are clear overlappings between the groups we got.


\section{K-Means algorithm}

In order to refine our grouping, we now apply the K-means algorithm.

First we need to remove the categorical variable **Gender** from the code because
the algorithm only supports numerical variables.

```{r}
malldtstd<-scale(malldt[,-1]) 
```

\subsection{Finding K}

Then we need to find the right value for k to use in the K-means algorithm.

```{r}
set.seed(42)
k.max<-15 

wss<-sapply(1:k.max,function(k){kmeans(malldtstd,k,nstart=50,iter.max=15)$tot.withinss})

plot(1:k.max,wss,type="b",pch=19,xlab="Number of groups",ylab="Within Deviation",col="blue") 
```

Let's try with k=4, k=5 and k=6 and evaluate their performances with the
**silhuotte method**.

\subsection{Silhoutte}

This refers to a method of interpretation and validation of consistency within clusters of data. The technique provides a succinct graphical representation of how well each object has been classified.

The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). The silhouette ranges from \-1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.

```{r, echo = T, results = 'hide'}
kmeans4<-kmeans(malldt[,-1],4)
kmeans5<-kmeans(malldt[,-1],5)
kmeans6<-kmeans(malldt[,-1],6)

# Evaluation of the clustering composition, images will be shown later
#ris4<- eclust(malldt[,-1],"kmeans",k=4)
#ris5<- eclust(malldt[,-1],"kmeans",k=5)
#ris6<- eclust(malldt[,-1],"kmeans",k=6)
```
```{r, include=FALSE}
ris4<- eclust(malldt[,-1],"kmeans",k=4)
ris5<- eclust(malldt[,-1],"kmeans",k=5)
ris6<- eclust(malldt[,-1],"kmeans",k=6)
```
```{r, echo = T, results = 'hide'}
# Dimensions and average of group's silhouette
avg_s_4 <- fviz_silhouette(ris4) + labs(title= "K = 4",
                                        subtitle= " Avg Silhoutte width: 0.39")
avg_s_5 <- fviz_silhouette(ris5) + labs(title= "K = 5",
                                        subtitle= " Avg Silhoutte width: 0.38")
avg_s_6 <- fviz_silhouette(ris6)+ labs(title= "K = 6",
                                        subtitle= " Avg Silhoutte width: 0.34")
```


```{r, echo=FALSE}
groups_4 <- readPNG("ris4.png")
groups_5 <- readPNG("ris5.png")
groups_6 <- readPNG("ris6.png")

grid.arrange(rasterGrob(groups_4), avg_s_4,
             rasterGrob(groups_5), avg_s_5,
             rasterGrob(groups_6), avg_s_6,
             ncol=2)

```


From the plots on the left we can see whether the groups are well defined or they overlap.
It is clear that the higher is the value of k, the bigger are the problems of overlapping.

Moreover, as we can see from the plots on the right, k=4 has also the best average silhouette value (0.39). From these plots it is also evident that k=4 has no observation with a negative silhouette value.

We decided to check this last point, searching for every exact observations with a negative silhouette value.


```{r}
# Silhouette measure of each observation
sil4<-ris4$silinfo$widths 
sil5<-ris5$silinfo$widths
sil6<-ris6$silinfo$widths

# Position of observation of silhouette < 0
neg_sil_index4<-which(sil4[,'sil_width']<0)
neg_sil_index5<-which(sil5[,'sil_width']<0)
neg_sil_index6<-which(sil6[,'sil_width']<0)

# Observations with silhouette < 0
sil4[neg_sil_index4,]
sil5[neg_sil_index5,]
sil6[neg_sil_index6,]

```

This again confirms that with k=4 we obtain zero observations with negative silhouette value, whereas with k=5 and k=6 we have respectively 7 and 10 observation of this kind.

Now that we have found the best value to use for 4, we plot another dendrogram using the Ward Method but splitting it in just 4 gorups.

```{r}
malldt.hc.ward.1<-hclust(malldt.dist,method="ward.D2") 
plot(malldt.hc.ward.1, main="Ward Method") 
rect.hclust(malldt.hc.ward.1,k=4,border=c("red","green","blue"))
```

Now let's see the means of the variables in the new groups to try and identify the characteristics that define the groups.

```{r}
# Allocate obs into 4 groups
malldt.groups.ward.1<-cutree(malldt.hc.ward.1 ,k=4) 
malldt.groups.ward.1

# Number of observations in each group
table(malldt.groups.ward.1)
```

```{r}
clusterdata.mean(malldt,malldt.groups.ward.1)
```

Now that the data is divided in 4 groups, some other observations can be done:
\begin{itemize}
\item \textbf{Gender}: the groups are still evenly split between females and males.
\item \textbf{Age}: there is also a pretty even split in age. Two groups contain people that are around 30 years old on average and two groups are composed of people who are around 50 years old on average.
\item \textbf{Annual income}: now the annual income is pretty even among the four groups, at around 60.000\$. 
\item \textbf{Spending Score}: the spending scores can again be split in two. Younger people have a higher spending score than older people.
\end{itemize}

At this point, looking at these results, we could name and describe the four groups in the following way:
\begin{itemize}
\item \textbf{Group 1}: \textbf{Young Females}, average annual income and high spending score.
\item \textbf{Group 2}: \textbf{Old Males}, average annual income and low spending score.
\item \textbf{Group 3}: \textbf{Young Males}, average annual income and high spending score.
\item \textbf{Group 4}: \textbf{Old Females}, average annual income and low spending score.
\end{itemize}

What emerged from this analysis is that for the same average annual income, younger people have a tendency to spend more than older people at a mall. Moreover, these spending habits seem not to be influenced by the gender of a given individual but solely by the age.

If we had to use this analysis to propose some kind of marketing strategy, we would suggest the mall to invest more in pushing the products that are frequently bought by young people, and implement a strategy to attract the older people that are evidently not buying as much as they could.  








