# mtry <- sqrt(ncol(train))
#
# tunegrid <- expand.grid(.mtry=mtry+6)
#
# train the model
# rf <- caret::train(stroke~.,
#                      data=train_smoted,
#                      method='rf',
#                      metric= metric,
#                      tuneGrid=tunegrid,
#                      trControl=control
#                      )
#saveRDS(rf, "rf_model.rds")
rf <- readRDS("rf_model.rds")
print(rf)
model_rf <- predict(rf, newdata = test)
tb <- table(Predicted = model_rf, Actual = test$stroke)[2:1, 2:1]
tb
print(paste0("Accuracy: ", (tb[1:1,1:1] + tb[2:2, 2:2])/(tb[1:1,2:2] + tb[2:2, 1:1] + tb[1:1,1:1] + tb[2:2, 2:2])))
print(paste0("F1: ", F_meas(tb)))
print(paste0("Recall: ", recall(tb)))
print(paste0("Precision: ", precision(tb)))
print(paste0('Accuracy:', round((tb[1:1,1:1] + tb[2:2, 2:2])/(tb[1:1,2:2] + tb[2:2, 1:1] + tb[1:1,1:1] + tb[2:2, 2:2]),2)))
print(paste0("F1: ", round(F_meas(tb),2)))
print(paste0("Recall: ", round(recall(tb),2)))
print(paste0("Precision: ", round(precision(tb),2)))
varImpPlot(rf)
# Explore possibilities with more "BlackBox" alghorithms like Random Forest
# Random Forest -----------------------------
for (i in 1:11) {
levels(train[,i]) <- make.names(c(levels(train[,i])))
}
for (i in 1:11) {
levels(test[,i]) <- make.names(c(levels(test[,i])))
}
#
# control <- trainControl(method='repeatedcv',
#                         number=3,
#                         repeats=5,
#                         search = "grid",
#                         #sampling = 'smote',
#                         allowParallel=T
#                         )
#
# # Metric compare model is Accuracy
# metric <- "Accuracy"
#
# #Number randomely variable selected is mtry
# mtry <- sqrt(ncol(train))
#
# tunegrid <- expand.grid(.mtry=mtry+6)
#
# train the model
# rf <- caret::train(stroke~.,
#                      data=train_smoted,
#                      method='rf',
#                      metric= metric,
#                      tuneGrid=tunegrid,
#                      trControl=control
#                      )
#saveRDS(rf, "rf_model.rds")
rf <- readRDS("rf_model.rds")
print(rf)
model_rf <- predict(rf, newdata = test)
tb <- table(Predicted = model_rf, Actual = test$stroke)[2:1, 2:1]
tb
print(paste0('Accuracy:', round((tb[1:1,1:1] + tb[2:2, 2:2])/(tb[1:1,2:2] + tb[2:2, 1:1] + tb[1:1,1:1] + tb[2:2, 2:2]),2)))
print(paste0("F1: ", round(F_meas(tb),2)))
print(paste0("Recall: ", round(recall(tb),2)))
print(paste0("Precision: ", round(precision(tb),2)))
varImpPlot(rf)
class(rf)
# Explore possibilities with more "BlackBox" alghorithms like Random Forest
# Random Forest -----------------------------
for (i in 1:11) {
levels(train[,i]) <- make.names(c(levels(train[,i])))
}
for (i in 1:11) {
levels(test[,i]) <- make.names(c(levels(test[,i])))
}
control <- trainControl(method='repeatedcv',
number=3,
repeats=5,
search = "grid",
#sampling = 'smote',
allowParallel=T
)
# Metric compare model is Accuracy
metric <- "Accuracy"
#Number randomely variable selected is mtry
mtry <- sqrt(ncol(train))
tunegrid <- expand.grid(.mtry=mtry+6)
train the model
# Explore possibilities with more "BlackBox" alghorithms like Random Forest
# Random Forest -----------------------------
for (i in 1:11) {
levels(train[,i]) <- make.names(c(levels(train[,i])))
}
for (i in 1:11) {
levels(test[,i]) <- make.names(c(levels(test[,i])))
}
control <- trainControl(method='repeatedcv',
number=3,
repeats=5,
search = "grid",
#sampling = 'smote',
allowParallel=T
)
# Metric compare model is Accuracy
metric <- "Accuracy"
#Number randomely variable selected is mtry
mtry <- sqrt(ncol(train))
tunegrid <- expand.grid(.mtry=mtry+6)
# train the model
rfss <- caret::train(stroke~.,
data=train_smoted,
method='rf',
metric= metric,
tuneGrid=tunegrid,
trControl=control
)
#saveRDS(rf, "rf_model.rds")
rf <- readRDS("rf_model.rds")
print(rf)
model_rf <- predict(rf, newdata = test)
tb <- table(Predicted = model_rf, Actual = test$stroke)[2:1, 2:1]
tb
varImpPlot(rfss)
caret::varImp(rf)
varImp(rf)
plot(varImp(rf))
# Load libraries
library(ggplot2)        # Basic plots
library(gridExtra)      # Multiple plot same figure
library(dplyr)          # Play w/ dataframes
library(broom)          # tidy()
library(GoodmanKruskal) # nice Corr Matrix
library(Hmisc)          # compute rcorr between quantitative vars
library(corrplot)       # plot nice corr matrix
library(caret)          # trainControl (train tree predictor)
library(pROC)
library(car)
library(randomForest)
#library(performanceEstimation)
###################################################################
# SMOTE stuff
library(ROCR)
remotes::install_github("dongyuanwu/RSBID")
library(RSBID) #cmd above to install it
###################################################################
# Set the current directory as working directory and load custom functions.
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
source("../utils/plots.R")
source("../utils/data_analysis.R")
# Load and summarize dataset
dataset = read.csv("stroke.csv")
str(dataset)
# Remove id column (useless)
dataset$id = NULL
# Convert qualitative variables in factors
dataset$gender          = factor(dataset$gender)
dataset$hypertension    = factor(dataset$hypertension, levels = c(0,1), labels = c("No", "Yes"))
dataset$heart_disease   = factor(dataset$heart_disease, levels = c(0,1), labels = c("No", "Yes"))
dataset$ever_married    = factor(dataset$ever_married)
dataset$work_type       = factor(dataset$work_type)
dataset$residence_type  = factor(dataset$Residence_type)
dataset$smoking_status  = factor(dataset$smoking_status)
dataset$stroke          = factor(dataset$stroke, levels = c(0,1), labels = c("No", "Yes"))
# Convert quantitative variable in numeric
dataset$bmi             = as.numeric(dataset$bmi)
# Remove duplicate column (due to uppercase)
dataset$Residence_type  = NULL
# Show dataset summary
str(dataset)
grid.arrange(ggplot(dataset, aes(x=stroke ,y=age)) +
geom_boxplot(fill= "#FDE725FF", alpha= 0.7),
ggplot(dataset, aes(x=stroke, y=bmi))+
geom_boxplot(fill= "#2D708EFF", alpha= 0.7),
ggplot(dataset, aes(x=stroke, y=avg_glucose_level))+
geom_boxplot(fill= "#440154FF", alpha= 0.7),
ncol=3)
grid.arrange(factors_plot(tidy(table(dataset %>% dplyr::select(stroke,work_type))), palette='Blues',
font_count_size=4, font_normalized_size=5.1, font_percentages_size=2.5,
font_categories_size=10),
factors_plot(tidy(table(dataset %>% dplyr::select(stroke,smoking_status))), palette='Greens',
font_count_size=4, font_normalized_size=5.1, font_percentages_size=2.5,
font_categories_size=10),
factors_plot(tidy(table(dataset %>% dplyr::select(stroke,gender))), palette='Purples',
font_count_size=4, font_normalized_size=5.1, font_percentages_size=2.5,
font_categories_size=10),
ncol=3, nrow=1)
grid.arrange(factors_plot(tidy(table(dataset %>% dplyr::select(stroke,hypertension))), palette='Greens',
font_count_size=3.5, font_normalized_size=5, font_percentages_size=2.5,
font_categories_size=10),
factors_plot(tidy(table(dataset %>% dplyr::select(stroke,heart_disease))), palette='Blues',
font_count_size=3.5, font_normalized_size=5, font_percentages_size=2.5,
font_categories_size=10),
factors_plot(tidy(table(dataset %>% dplyr::select(stroke,residence_type))), palette='Purples',
font_count_size=3.5, font_normalized_size=5, font_percentages_size=2.5,
font_categories_size=10),
factors_plot(tidy(table(dataset %>% dplyr::select(stroke,ever_married))), palette='Oranges',
font_count_size=3.5, font_normalized_size=5, font_percentages_size=2.5,
font_categories_size=10),
ncol=2, nrow=2)
qualitative_vars = c('gender', 'hypertension', 'heart_disease', 'ever_married',
'work_type', 'smoking_status', 'residence_type')
plot(GKtauDataframe(dataset %>% dplyr::select(all_of(qualitative_vars))))
quantitative_vars = c('age', 'avg_glucose_level', 'bmi')
corr <- rcorr(as.matrix(dataset %>% dplyr::select(all_of(quantitative_vars))))
corrplot(corr$r, type = "upper", tl.col = "black", tl.srt = 45)
factors_plot(tidy(table(dataset %>% dplyr::select(ever_married,work_type))), palette='Blues',
font_count_size=4, font_normalized_size=5.1, font_percentages_size=2.5,
font_categories_size=10)
#finding the intercept to use in the next plot
fit <- lm(bmi~age, data=dataset)
fit
plot(x=dataset$age, y=dataset$bmi) +
lines(0:100, c(0:100)*0.2+23, col='red')
# Remove rows
dataset = dataset %>%
filter(gender != 'Other') %>%
filter(work_type != 'Never_worked')
# Remove related levels
dataset = droplevels(dataset)
# Check for NA in all columns
for (col_name in colnames(dataset)){
if (anyNA(dataset[[col_name]]))
print(paste(col_name, '-> ', sum(is.na(dataset[[col_name]])), ' NA'))
}
# Define test set as set with missing data
missing_index <- which(is.na(dataset$bmi))
test_set <- dataset[missing_index,]
train_set <- dataset[-c(missing_index),]
# Fit the tree
tree = caret::train(bmi ~ .,
data=train_set,
method="rpart",
trControl = trainControl(method = "cv"))
# Replace missing data with predicted data
bmi_pred <- predict(tree, newdata = test_set)
dataset[missing_index, 'bmi'] <- bmi_pred
# clean global environment
rm(test_set, train_set, tree, bmi_pred, missing_index)
# Set a fixed seed in order to have reproducible results
set.seed(42)
# 60-40 split
split_train_test <- createDataPartition(y = dataset$stroke, p=0.6, list = F)
train <- dataset[split_train_test,]
test <-  dataset[-split_train_test,]
print(table(train$stroke))
print(table(test$stroke))
# New smote algorithm
train_smoted <- SMOTE_NC(train, "stroke", k = 2, perc_maj = 50)
# Now we have a balanced dataset
print(print(paste0('This was the regular training set:', table(train$stroke))))
print('This is the oversampled one with a more balanced dataset')
table(train_smoted$stroke)
Logit <- glm(stroke~., data=train_smoted, family = binomial(link = "logit"))
summary(Logit)
vif(Logit)
library(caret)
lr_prob1 <- predict(Logit, newdata = test, type = "response")
lr_pred1 <- ifelse(lr_prob1 > 0.65,"Yes","No")
tb <- table(Predicted = lr_pred1, Actual = test$stroke)[2:1, 2:1]
tb
print(paste0("Accuracy: ", (tb[1:1,1:1] + tb[2:2, 2:2])/(tb[1:1,2:2] + tb[2:2, 1:1] + tb[1:1,1:1] + tb[2:2, 2:2])))
print(paste0("F1: ", F_meas(tb)))
print(paste0("Recall: ", recall(tb)))
print(paste0("Precision: ", precision(tb)))
library(caret)
lr_prob1 <- predict(Logit, newdata = test, type = "response")
lr_pred1 <- ifelse(lr_prob1 > 0.65,"Yes","No")
tb <- table(Predicted = lr_pred1, Actual = test$stroke)[2:1, 2:1]
tb
print(paste0("Accuracy: ", (tb[1:1,1:1] + tb[2:2, 2:2])/(tb[1:1,2:2] + tb[2:2, 1:1] + tb[1:1,1:1] + tb[2:2, 2:2])))
print(paste0("F1: ", F_meas(tb)))
print(paste0("Recall: ", recall(tb)))
print(paste0("Precision: ", precision(tb)))
library(caret)
lr_prob1 <- predict(Logit, newdata = test, type = "response")
lr_pred1 <- ifelse(lr_prob1 > 0.65,"Yes","No")
tb <- table(Predicted = lr_pred1, Actual = test$stroke)[2:1, 2:1]
tb
print(paste0("Accuracy: ", (tb[1:1,1:1] + tb[2:2, 2:2])/(tb[1:1,2:2] + tb[2:2, 1:1] + tb[1:1,1:1] + tb[2:2, 2:2])))
print(paste0("F1: ", F_meas(tb)))
print(paste0("Recall: ", recall(tb)))
print(paste0("Precision: ", precision(tb)))
confusionMatrix(tb)
gbmGrid <- expand.grid(nIter=c(88,102,112,120,135))
trctrl <- trainControl(method = "cv"
, number = 10
#, repeats = 10
#, search = "random"
, classProbs = T
, summaryFunction = twoClassSummary
)
logit_fit <- train(stroke ~., data = train_smoted, method = "LogitBoost", trControl=trctrl,
tuneGrid=gbmGrid,
metric= "ROC"
)
logit_fit
pred <- round(predict(logit_fit, newdata = test, type = "prob"),3)
pred <- as.factor(ifelse(pred[2] > 0.5,'Yes','No'))
tb <- table(Predicted = pred, Actual = test$stroke)[2:1, 2:1]
tb
print(paste0('Accuracy:', round((tb[1:1,1:1] + tb[2:2, 2:2])/(tb[1:1,2:2] + tb[2:2, 1:1] + tb[1:1,1:1] + tb[2:2, 2:2]),2)))
print(paste0("F1: ", round(F_meas(tb),2)))
print(paste0("Recall: ", round(recall(tb),2)))
print(paste0("Precision: ", round(precision(tb),2)))
View(test)
lr_prob1
pred
pred[2]
pred <- round(predict(logit_fit, newdata = test, type = "prob"),3)
test_roc <- roc(as.numeric(test$stroke)~pred[2] , plot = TRUE, print.auc = TRUE,percent=TRUE, ci=TRUE)
pred
pred[2]
as.numeric(pred[2])
as.numeric(as.numeric(test$stroke)
c
as.numeric(test$stroke
c
as.numeric(test$stroke)
class(as.numeric(test$stroke)
)
Logit <- glm(stroke~., data=train_smoted, family = binomial(link = "logit"))
summary(Logit)
vif(Logit)
library(caret)
lr_prob1 <- predict(Logit, newdata = test, type = "response")
lr_pred1 <- ifelse(lr_prob1 > 0.65,"Yes","No")
tb <- table(Predicted = lr_pred1, Actual = test$stroke)[2:1, 2:1]
confusionMatrix(tb)
print(paste0("F1: ", F_meas(tb)))
test_roc <- roc(as.numeric(test$stroke)~lr_prob1 , plot = TRUE, print.auc = TRUE,percent=TRUE, ci=TRUE)
as.numeric(test$stroke)
lr_prob1
gbmGrid <- expand.grid(nIter=c(88,102,112,120,135))
trctrl <- trainControl(method = "cv"
, number = 10
#, repeats = 10
#, search = "random"
, classProbs = T
, summaryFunction = twoClassSummary
)
logit_fit <- train(stroke ~., data = train_smoted, method = "LogitBoost", trControl=trctrl,
tuneGrid=gbmGrid,
metric= "ROC"
)
logit_fit
plot(logit_fit)
pred <- round(predict(logit_fit, newdata = test, type = "prob"),3)
test_roc <- roc(as.numeric(test$stroke)~pred[2] , plot = TRUE, print.auc = TRUE,percent=TRUE, ci=TRUE)
pred <- round(predict(logit_fit, newdata = test, type = "response"),3)
pred <- round(predict(logit_fit, newdata = test, type = "response"),3)
pred <- round(predict(logit_fit, newdata = test, type = "prob"),3)
test_roc <- roc(as.numeric(test$stroke)~pred[2] , plot = TRUE, print.auc = TRUE,percent=TRUE, ci=TRUE)
pred <- round(predict(logit_fit, newdata = test, type = "prob"),3)
test_roc <- roc(as.numeric(test$stroke)~pred , plot = TRUE, print.auc = TRUE,percent=TRUE, ci=TRUE)
pred
prob <- pred[2]
prob
as.numeric(prob)
class(lr_prob1)
prob <- unlist(pred[2])
pred <- round(predict(logit_fit, newdata = test, type = "prob"),3)
prob <- unlist(pred[2])
test_roc <- roc(as.numeric(test$stroke)~prob , plot = TRUE, print.auc = TRUE,percent=TRUE, ci=TRUE)
pred <- round(predict(logit_fit, newdata = test, type = "prob"),3)
prob <- unlist(pred[1])
test_roc <- roc(as.numeric(test$stroke)~prob , plot = TRUE, print.auc = TRUE,percent=TRUE, ci=TRUE)
pred <- round(predict(logit_fit, newdata = test, type = "prob"),3)
prob <- unlist(pred[2])
test_roc <- roc(as.numeric(test$stroke)~prob , plot = TRUE, print.auc = TRUE,percent=TRUE, ci=TRUE)
prob
View(pred)
pred <- as.factor(ifelse(pred[2] > 0.5,'Yes','No'))
tb <- table(Predicted = pred, Actual = test$stroke)[2:1, 2:1]
tb
print(paste0('Accuracy:', round((tb[1:1,1:1] + tb[2:2, 2:2])/(tb[1:1,2:2] + tb[2:2, 1:1] + tb[1:1,1:1] + tb[2:2, 2:2]),2)))
print(paste0("F1: ", round(F_meas(tb),2)))
print(paste0("Recall: ", round(recall(tb),2)))
print(paste0("Precision: ", round(precision(tb),2)))
pred <- as.factor(ifelse(pred[2] > 0.5,'Yes','No'))
tb <- table(Predicted = pred, Actual = test$stroke)[2:1, 2:1]
pred <- as.factor(ifelse(pred[2] > 0.5,'Yes','No'))
tb <- table(Predicted = pred, Actual = test$stroke)[2:1, 2:1]
# Explore possibilities with more "BlackBox" alghorithms like Random Forest
# Random Forest -----------------------------
for (i in 1:11) {
levels(train[,i]) <- make.names(c(levels(train[,i])))
}
for (i in 1:11) {
levels(test[,i]) <- make.names(c(levels(test[,i])))
}
control <- trainControl(method='repeatedcv',
number=3,
repeats=5,
search = "grid",
#sampling = 'smote',
allowParallel=T
)
# Metric compare model is Accuracy
metric <- "Accuracy"
#Number randomely variable selected is mtry
mtry <- sqrt(ncol(train))
tunegrid <- expand.grid(.mtry=mtry+6)
# train the model
# rfss <- caret::train(stroke~.,
#                      data=train_smoted,
#                      method='rf',
#                      metric= metric,
#                      tuneGrid=tunegrid,
#                      trControl=control
#                      )
#saveRDS(rf, "rf_model.rds")
rf <- readRDS("rf_model.rds")
print(rf)
model_rf <- predict(rf, newdata = test)
tb <- table(Predicted = model_rf, Actual = test$stroke)[2:1, 2:1]
tb
print(paste0('Accuracy:', round((tb[1:1,1:1] + tb[2:2, 2:2])/(tb[1:1,2:2] + tb[2:2, 1:1] + tb[1:1,1:1] + tb[2:2, 2:2]),2)))
print(paste0("F1: ", round(F_meas(tb),2)))
print(paste0("Recall: ", round(recall(tb),2)))
print(paste0("Precision: ", round(precision(tb),2)))
model_rf
# Explore possibilities with more "BlackBox" alghorithms like Random Forest
# Random Forest -----------------------------
for (i in 1:11) {
levels(train[,i]) <- make.names(c(levels(train[,i])))
}
for (i in 1:11) {
levels(test[,i]) <- make.names(c(levels(test[,i])))
}
control <- trainControl(method='repeatedcv',
number=3,
repeats=5,
search = "grid",
#sampling = 'smote',
allowParallel=T
)
# Metric compare model is Accuracy
metric <- "Accuracy"
#Number randomely variable selected is mtry
mtry <- sqrt(ncol(train))
tunegrid <- expand.grid(.mtry=mtry+6)
# train the model
# rfss <- caret::train(stroke~.,
#                      data=train_smoted,
#                      method='rf',
#                      metric= metric,
#                      tuneGrid=tunegrid,
#                      trControl=control
#                      )
#saveRDS(rf, "rf_model.rds")
rf <- readRDS("rf_model.rds")
print(rf)
model_rf <- predict(rf, newdata = test)
model_rf_prob <- predict(rf, newdata = test, type = prob)
# Explore possibilities with more "BlackBox" alghorithms like Random Forest
# Random Forest -----------------------------
for (i in 1:11) {
levels(train[,i]) <- make.names(c(levels(train[,i])))
}
for (i in 1:11) {
levels(test[,i]) <- make.names(c(levels(test[,i])))
}
control <- trainControl(method='repeatedcv',
number=3,
repeats=5,
search = "grid",
#sampling = 'smote',
allowParallel=T
)
# Metric compare model is Accuracy
metric <- "Accuracy"
#Number randomely variable selected is mtry
mtry <- sqrt(ncol(train))
tunegrid <- expand.grid(.mtry=mtry+6)
# train the model
# rfss <- caret::train(stroke~.,
#                      data=train_smoted,
#                      method='rf',
#                      metric= metric,
#                      tuneGrid=tunegrid,
#                      trControl=control
#                      )
#saveRDS(rf, "rf_model.rds")
rf <- readRDS("rf_model.rds")
print(rf)
model_rf <- predict(rf, newdata = test)
model_rf_prob <- predict(rf, newdata = test, type = 'prob')
tb <- table(Predicted = model_rf, Actual = test$stroke)[2:1, 2:1]
tb
print(paste0('Accuracy:', round((tb[1:1,1:1] + tb[2:2, 2:2])/(tb[1:1,2:2] + tb[2:2, 1:1] + tb[1:1,1:1] + tb[2:2, 2:2]),2)))
print(paste0("F1: ", round(F_meas(tb),2)))
print(paste0("Recall: ", round(recall(tb),2)))
print(paste0("Precision: ", round(precision(tb),2)))
tb <- table(Predicted = model_rf, Actual = test$stroke)[2:1, 2:1]
tb
confusionMatrix(tb)
print(paste0('Accuracy:', round((tb[1:1,1:1] + tb[2:2, 2:2])/(tb[1:1,2:2] + tb[2:2, 1:1] + tb[1:1,1:1] + tb[2:2, 2:2]),2)))
print(paste0("F1: ", round(F_meas(tb),2)))
print(paste0("Recall: ", round(recall(tb),2)))
print(paste0("Precision: ", round(precision(tb),2)))
model_rf_prob
test_roc <- roc(as.numeric(test$stroke)~as.numeric(unlist(model_rf_prob)) , plot = TRUE, print.auc = TRUE,percent=TRUE, ci=TRUE)
test_roc <- roc(as.numeric(test$stroke)~as.numeric(unlist(model_rf_prob[2])) , plot = TRUE, print.auc = TRUE,percent=TRUE, ci=TRUE)
plot(varImp(rf))
tb <- table(Predicted = model_rf, Actual = test$stroke)[2:1, 2:1]
confusionMatrix(tb)
print(paste0("F1: ", round(F_meas(tb),2)))
