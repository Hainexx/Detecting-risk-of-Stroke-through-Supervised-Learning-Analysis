library(Hmisc)          # compute rcorr between quantitative vars
library(corrplot)       # plot nice corr matrix
###################################################################
# SMOTE stuff
library(ROCR)
install.packages("ROCR")
library(corrplot)
library(performanceEstimation)
set.seed(42)
###################################################################
# SMOTE stuff
library(ROCR)
# Set current directory as WD
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
source("../utils/plots.R")
source("../utils/data_analysis.R")
source("../utils/plots.R")
source("../utils/data_analysis.R")
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
stroke <- read_csv("stroke.csv", col_types = cols(hypertension = col_factor(levels = c("0","1")),
heart_disease = col_factor(levels = c("0","1")),
ever_married = col_factor(levels = c("Yes","No")),
bmi = col_double(),
stroke = col_factor(levels = c("0", "1")),
Residence_type = col_factor(levels = c("Urban","Rural"))))
setwd("C:/Users/ACESF31452570N/Desktop/Università/DSE/Machine Learning/Salini_Stat_Learning/group")
stroke <- read_csv("stroke.csv", col_types = cols(hypertension = col_factor(levels = c("0","1")),
heart_disease = col_factor(levels = c("0","1")),
ever_married = col_factor(levels = c("Yes","No")),
bmi = col_double(),
stroke = col_factor(levels = c("0", "1")),
Residence_type = col_factor(levels = c("Urban","Rural"))))
setwd("C:/Users/ACESF31452570N/Desktop/Università/DSE/Machine Learning/Salini_Stat_Learning/group/first_paper")
stroke <- read_csv("stroke.csv", col_types = cols(hypertension = col_factor(levels = c("0","1")),
heart_disease = col_factor(levels = c("0","1")),
ever_married = col_factor(levels = c("Yes","No")),
bmi = col_double(),
stroke = col_factor(levels = c("0", "1")),
Residence_type = col_factor(levels = c("Urban","Rural"))))
set.seed(42)
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
stroke <- read_csv("stroke.csv", col_types = cols(hypertension = col_factor(levels = c("0","1")),
heart_disease = col_factor(levels = c("0","1")),
ever_married = col_factor(levels = c("Yes","No")),
bmi = col_double(),
stroke = col_factor(levels = c("0", "1")),
Residence_type = col_factor(levels = c("Urban","Rural"))))
library(readr)
library(tidyverse)
library(Hmisc)
library(DMwR)
library(gmodels)
library(GoodmanKruskal)
library(corrplot)
library(pscl)
library(caret)
library(pROC)
library(readr)
library(GoodmanKruskal)
library(corrplot)
library(performanceEstimation)
set.seed(42)
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
stroke <- read_csv("stroke.csv", col_types = cols(hypertension = col_factor(levels = c("0","1")),
heart_disease = col_factor(levels = c("0","1")),
ever_married = col_factor(levels = c("Yes","No")),
bmi = col_double(),
stroke = col_factor(levels = c("0", "1")),
Residence_type = col_factor(levels = c("Urban","Rural"))))
# data manipulation ----------------------------------
stroke$id <- NULL
stroke$smoking_status <- as.factor(stroke$smoking_status)
# rm gender "other"
stroke <- stroke[stroke$gender == "Male" | stroke$gender == "Female",]
stroke$gender <- as.factor(stroke$gender)
# rm "Never_worked"
stroke <- stroke[!stroke$work_type == "Never_worked",]
stroke$work_type <- as.factor(stroke$work_type)
# data visualization ----------------------------------
ggplot(stroke, aes(x=as.factor(stroke),y=age))+
geom_boxplot(fill= "darkred", alpha= 0.7)
ggplot(stroke, aes(x=as.factor(stroke),y=bmi))+
geom_boxplot(fill= "darkred", alpha= 0.7)
# deal with NAs -------------------------------
stroke <- as_tibble(stroke)
sum(is.na(stroke$bmi))
missing_index <- which(is.na(stroke$bmi))
X <- stroke[missing_index,]
train_v <- stroke[-c(missing_index),]
tree = caret::train(bmi ~ .,
data=train_v,
method="rpart",
trControl = trainControl(method = "cv"))
bmi_pred <- predict(tree, newdata = X)
stroke[missing_index,"bmi"] <- bmi_pred
sum(is.na(stroke$bmi))
sum(is.na(stroke))
# check for other NAs
for (i in 1:11) {
print(which(is.na(stroke[,i])))
}
# clean Glob_Env
rm(train_v,X,tree, bmi_pred,i,missing_index)
# qualitative corr ----------------------------------
dt.gk<-stroke
dt.gk$stroke<-NULL
dt.gk$bmi<-NULL
dt.gk$age<-NULL
dt.gk$avg_glucose_level<-NULL
plot(GKtauDataframe(dt.gk))
# quantitative corr ---------------------------------
num <- stroke[c("age","avg_glucose_level","bmi")]
corr <- rcorr(as.matrix(num))
flattenCorrMatrix <- function(cormat, pmat) {
ut <- upper.tri(cormat)
data.frame(
row = rownames(cormat)[row(cormat)[ut]],
column = rownames(cormat)[col(cormat)[ut]],
cor  =(cormat)[ut],
p = pmat[ut]
)
}
flattenCorrMatrix(corr$r, corr$P)
corrplot(corr$r, type = "upper", tl.col = "black", tl.srt = 45)
# train & test --------------------------------------
set.seed(42)
stroke <- as.data.frame(stroke)
for (i in 1:11) {
levels(stroke[,i]) <- make.names(c(levels(stroke[,i])))
}
split_train_test <- createDataPartition(y = stroke$stroke, p=0.5, list = F)
train <- stroke[split_train_test,]
test <-  stroke[-split_train_test,]
train <- smote(stroke ~ ., train, perc.over = 11, perc.under=2)
# Now we have a balanced dataset
length(which(train$stroke == "X1"))
length(which(train$stroke == "X0"))
child <- train[train$work_type == "children",]
summary(child$age)
# Regression ----------------------------------------
Logit <- glm(stroke~., data=train, family = binomial(link = "logit"))
Logit
lr_prob1 <- predict(Logit, newdata = test, type="response")
lr_preds_test <- c(0,0,0,0,0,0,0,0,0,0,0)
i<-1
for (thresh in seq(0.25,0.75,0.05)){
lr_pred <- ifelse(lr_prob1 > thresh,1,0)
cm <- table(
as.factor(lr_pred),
as.factor(test$stroke)
)[2:1, 2:1]
lr_preds_test[i] <- F_meas(cm)
i<-i+1
}
names(lr_preds_test) <- seq(0.25,0.75,0.05)
lr_preds_test
lr_pred <- as.numeric(ifelse(lr_prob1 > 0.65,"1","0"))
tb <- table(Predicted = lr_pred, Actual = test$stroke)[2:1, 2:1]
tb
(tb[1:1,1:1] + tb[2:2, 2:2])/(tb[1:1,2:2] + tb[2:2, 1:1] + tb[1:1,1:1] + tb[2:2, 2:2]) #Accuracy
F_meas(tb) # F1
recall(tb)  # Recall
precision(tb) # Precision
test_roc <- roc(as.numeric(test$stroke)~lr_prob1 , plot = TRUE, print.auc = TRUE,percent=TRUE, ci=TRUE)
# LogitBoost
gbmGrid <- expand.grid(nIter=c(16,96,102))
trctrl <- trainControl(method = "repeatedcv"
, number = 10
, repeats = 10
, savePredictions=TRUE
, search = "random"
, classProbs = T
, summaryFunction = twoClassSummary
)
logit_fit <- train(stroke ~., data = train, method = "LogitBoost", trControl=trctrl, metric = "ROC",tuneGrid=gbmGrid)
logit_fit
trellis.par.set(caretTheme())
plot(logit_fit)
lr_prob1 <- predict(logit_fit, newdata = test
, type = "prob"
)
lr_preds_test <- c(0,0,0,0,0,0,0,0,0,0,0)
i<-1
for (thresh in seq(0.25,0.75,0.05)){
lr_pred <- ifelse(lr_prob1 > thresh,1,0)
cm <- table(
as.factor(lr_pred),
as.factor(test$stroke)
)[2:1, 2:1]
lr_preds_test[i] <- F_meas(cm)
i<-i+1
}
names(lr_preds_test) <- seq(0.25,0.75,0.05)
lr_preds_test
#lr_prob1 <- predict(Logit, newdata = test, type="response")
lr_pred <- as.factor(ifelse(pred[,2] > 0.49,"1","0"))
tb <- table(Predicted = lr_pred, Actual = test$stroke)[2:1, 2:1]
tb
(tb[1:1,1:1] + tb[2:2, 2:2])/(tb[1:1,2:2] + tb[2:2, 1:1] + tb[1:1,1:1] + tb[2:2, 2:2]) #Accuracy
F_meas(tb) # F1
recall(tb)  # Recall
precision(tb) # Precision
#10 folds repeat 3 times
control <- trainControl(method='repeatedcv',
number=10,
repeats=3,
#search = "random",
#classProbs = TRUE
)
#Metric compare model is Accuracy
metric <- "Accuracy"
#Number randomely variable selected is mtry
mtry <- sqrt(ncol(train))
tunegrid <- expand.grid(.mtry=rnorm(5,mean=mtry,sd=1))
rf <- caret::train(stroke~.,
data=train,
method='rf',
metric= metric,
tuneGrid=tunegrid,
trControl=control)
library(cluster)
library(readr)
library(corrplot)
library(factoextra)
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
malldt <- read_csv("Mall_Customers.csv")
malldt$CustomerID <- NULL
View(malldt)
View(malldt)
malldt$CustomerID <- NULL
View(malldt)
View(malldt)
malldt$Gender <- as.factor(malldt$Gender)
malldt.dist<-daisy(malldt,metric="euclidean",stand=TRUE)
malldt.hc.com<-hclust(malldt.dist,method="complete")
plot(malldt.hc.com)
rect.hclust(malldt.hc.com,k=3,border=c("red","green","blue"))
malldt.hc.sin<-hclust(malldt.dist,method="single")
plot(malldt.hc.sin)
malldt.hc.ward<-hclust(malldt.dist,method="ward")
plot(malldt.hc.ward)
rect.hclust(malldt.hc.ward,k=3,border=c("red","green","blue"))
malldtstd<-scale(malldt[,-1])
library(tidyverse)
library(Hmisc)
library(DMwR)
library(gmodels)
library(GoodmanKruskal)
library(corrplot)
library(pscl)
library(caret)
library(pROC)
library(readr)
library(GoodmanKruskal)
library(corrplot)
library(performanceEstimation)
set.seed(42)
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
stroke <- read_csv("stroke.csv", col_types = cols(hypertension = col_factor(levels = c("0","1")),
heart_disease = col_factor(levels = c("0","1")),
ever_married = col_factor(levels = c("Yes","No")),
bmi = col_double(),
stroke = col_factor(levels = c("0", "1")),
Residence_type = col_factor(levels = c("Urban","Rural"))))
# data manipulation ----------------------------------
stroke$id <- NULL
stroke$smoking_status <- as.factor(stroke$smoking_status)
# rm gender "other"
stroke <- stroke[stroke$gender == "Male" | stroke$gender == "Female",]
stroke$gender <- as.factor(stroke$gender)
# rm "Never_worked"
stroke <- stroke[!stroke$work_type == "Never_worked",]
stroke$work_type <- as.factor(stroke$work_type)
# deal with NAs -------------------------------
stroke <- as_tibble(stroke)
sum(is.na(stroke$bmi))
missing_index <- which(is.na(stroke$bmi))
X <- stroke[missing_index,]
train_v <- stroke[-c(missing_index),]
tree = caret::train(bmi ~ .,
data=train_v,
method="rpart",
trControl = trainControl(method = "cv"))
bmi_pred <- predict(tree, newdata = X)
stroke[missing_index,"bmi"] <- bmi_pred
sum(is.na(stroke$bmi))
sum(is.na(stroke))
# check for other NAs
for (i in 1:11) {
print(which(is.na(stroke[,i])))
}
# clean Glob_Env
rm(train_v,X,tree, bmi_pred,i,missing_index)
# qualitative corr ----------------------------------
dt.gk<-stroke
dt.gk$stroke<-NULL
dt.gk$bmi<-NULL
dt.gk$age<-NULL
dt.gk$avg_glucose_level<-NULL
plot(GKtauDataframe(dt.gk))
# quantitative corr ---------------------------------
num <- stroke[c("age","avg_glucose_level","bmi")]
View(dt.gk)
View(dt.gk)
corr <- rcorr(as.matrix(num))
flattenCorrMatrix <- function(cormat, pmat) {
ut <- upper.tri(cormat)
data.frame(
row = rownames(cormat)[row(cormat)[ut]],
column = rownames(cormat)[col(cormat)[ut]],
cor  =(cormat)[ut],
p = pmat[ut]
)
}
flattenCorrMatrix(corr$r, corr$P)
corrplot(corr$r, type = "upper", tl.col = "black", tl.srt = 45)
Logit <- glm(stroke~., data=train, family = binomial(link = "logit"))
library(ggplot2)        # Basic plots
library(gridExtra)      # Multiple plot same figure
# library(cvms)           # Confusion Matrix
library(dplyr)          # Play w/ dataframes
library(broom)          # tidy()
library(GoodmanKruskal) # nice Corr Matrix
library(Hmisc)          # compute rcorr between quantitative vars
library(corrplot)       # plot nice corr matrix
library(performanceEstimation)
library(tidyverse)
library(Hmisc)
#library(DMwR)
library(gmodels)
library(GoodmanKruskal)
library(corrplot)
library(pscl)
library(caret)
library(pROC)
library(readr)
library(GoodmanKruskal)
library(corrplot)
library(performanceEstimation)
###################################################################
# SMOTE stuff
library(ROCR)
###################################################################
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
source("../utils/plots.R")
source("../utils/data_analysis.R")
dataset = read.csv("stroke.csv")
str(dataset)
dataset$id = NULL
dataset$gender = factor(dataset$gender)
dataset$hypertension = factor(dataset$hypertension, levels = c(0,1), labels = c("No", "Yes"))
dataset$heart_disease = factor(dataset$heart_disease, levels = c(0,1), labels = c("No", "Yes"))
dataset$ever_married = factor(dataset$ever_married)
dataset$work_type = factor(dataset$work_type)
dataset$residence_type = factor(dataset$Residence_type)
dataset$Residence_type = NULL
dataset$smoking_status = factor(dataset$smoking_status)
dataset$stroke = factor(dataset$stroke, levels = c(0,1), labels = c("No", "Yes"))
dataset$bmi = as.numeric(dataset$bmi)
str(dataset)
grid.arrange(ggplot(dataset, aes(x=stroke ,y=age)) +
geom_boxplot(fill= "#FDE725FF", alpha= 0.7),
ggplot(dataset, aes(x=stroke, y=bmi))+
geom_boxplot(fill= "#2D708EFF", alpha= 0.7),
ggplot(dataset, aes(x=stroke, y=avg_glucose_level))+
geom_boxplot(fill= "#440154FF", alpha= 0.7),
ncol=3)
source("../utils/plots.R")
#,fig.height=12
grid.arrange(factors_plot(tidy(table(dataset %>% select(stroke,work_type))), palette='Blues',
font_count_size=4, font_normalized_size=5.1, font_percentages_size=2.5,
font_categories_size=10),
factors_plot(tidy(table(dataset %>% select(stroke,smoking_status))), palette='Greens',
font_count_size=4, font_normalized_size=5.1, font_percentages_size=2.5,
font_categories_size=10),
factors_plot(tidy(table(dataset %>% select(stroke,gender))), palette='Purples',
font_count_size=4, font_normalized_size=5.1, font_percentages_size=2.5,
font_categories_size=10),
ncol=3, nrow=1)
grid.arrange(factors_plot(tidy(table(dataset %>% select(stroke,hypertension))), palette='Greens',
font_count_size=4.5, font_normalized_size=6, font_percentages_size=3.5,
font_categories_size=10),
factors_plot(tidy(table(dataset %>% select(stroke,heart_disease))), palette='Blues',
font_count_size=4.5, font_normalized_size=6, font_percentages_size=3.5,
font_categories_size=10),
factors_plot(tidy(table(dataset %>% select(stroke,residence_type))), palette='Purples',
font_count_size=4.5, font_normalized_size=6, font_percentages_size=3.5,
font_categories_size=10),
factors_plot(tidy(table(dataset %>% select(stroke,ever_married))), palette='Oranges',
font_count_size=4.5, font_normalized_size=6, font_percentages_size=3.5,
font_categories_size=10),
ncol=2, nrow=2)
qualitative_vars = c('gender', 'hypertension', 'heart_disease', 'ever_married',
'work_type', 'smoking_status', 'residence_type')
plot(GKtauDataframe(dataset %>% select(all_of(qualitative_vars))))
# TODO find a way to plot table and image side-by-side
quantitative_vars = c('age', 'avg_glucose_level', 'bmi')
corr <- rcorr(as.matrix(dataset %>% select(all_of(quantitative_vars))))
corrplot(corr$r, type = "upper", tl.col = "black", tl.srt = 45)
#flattenCorrMatrix(corr$r, corr$P)
# rm gender "other"
dataset$gender <- as.character(dataset$gender)
stroke <- dataset[dataset$gender == "Male" | dataset$gender == "Female",]
stroke$gender <- as.factor(stroke$gender)
# rm "Never_worked"
dataset$work_type <- as.character(dataset$work_type)
stroke <- dataset[!dataset$work_type == "Never_worked",]
stroke$work_type <- as.factor(stroke$work_type)
stroke <- as_tibble(stroke)
sum(is.na(stroke$bmi))
missing_index <- which(is.na(stroke$bmi))
X <- stroke[missing_index,]
train_v <- stroke[-c(missing_index),]
tree = caret::train(bmi ~ .,
data=train_v,
method="rpart",
trControl = trainControl(method = "cv"))
bmi_pred <- predict(tree, newdata = X)
stroke[missing_index,"bmi"] <- bmi_pred
sum(is.na(stroke$bmi))
sum(is.na(stroke))
# check for other NAs
for (i in 1:11) {
print(which(is.na(stroke[,i])))
}
# clean Glob_Env
rm(train_v,X,tree, bmi_pred,i,missing_index)
set.seed(42)
stroke <- as.data.frame(stroke)
for (i in 1:11) {
levels(stroke[,i]) <- make.names(c(levels(stroke[,i])))
}
split_train_test <- createDataPartition(y = stroke$stroke, p=0.5, list = F)
train <- stroke[split_train_test,]
test <-  stroke[-split_train_test,]
# new smote algo
Logit <- glm(stroke~., data=train, family = binomial(link = "logit"))
Logit
# TODO clean code and stuff
# data Preprocessing, Econding with OneHotEncoding ------------------------------
#
#dummy <- dummyVars(" ~ gender + work_type + smoking_status + ever_married + Residence_type", data=stroke)
#newdata <- data.frame(predict(dummy, newdata = stroke))
#a <- stroke[,2:4]
#b <- stroke[,8:9]
#dt <- cbind(a, b, newdata, stroke['stroke'])
#dt <- as_tibble(dt)
#
#y <- stroke['stroke']
# Fill missing bmi data w/ tree prediction
# TODO keep this way? should we just remove them?
#
# missing_index <-which(is.na(dataset$bmi))
#
# train_set <- dataset[-c(missing_index),]
#
# tree = caret::train(bmi ~ .,
#                     data=train_set,
#                     method="rpart",
#                     trControl = trainControl(method = "cv"))
# predicted_bmi <- predict(tree, newdata = dataset[missing_index,])
#
# #######################
# # What? Why?
# # x <- mean(bmi_pred)
# # bmi_pred[202] <- x
# #######################
#
# dataset[missing_index,"bmi"] <- predicted_bmi
#
# dataset = na.omit(dataset)
#
# # Check quantitative correlation is under control w/ new data
# TODO side by side :)
#
# new_corr <- rcorr(as.matrix(dataset %>% select(all_of(quantitative_vars))))
# flattenCorrMatrix(new_corr$r, new_corr$P)
#
# grid.arrange(corrplot(corr$r,    type = "upper", tl.col = "black", tl.srt = 45),
#             corrplot(new_corr$r, type = "upper", tl.col = "black", tl.srt = 45),
#             ncol=2, nrow=1)
# Solve the under sampling problem with SMOTE algho to create synth new data
# dataset <- as.data.frame(lapply(dataset, as.factor)) # What? Why?
#
# trainSplit <- DMwR::SMOTE(stroke ~ ., dt, perc.over = 2000, perc.under=10)
#
# dt_synth<- rbind(trainSplit,dt)
#
#
# dt_synth$work_type.Never_worked <- NULL # Again, but why :D
#
# dt_synth$avg_glucose_level <- as.numeric(dt_synth$avg_glucose_level)
# dt_synth$bmi <- as.numeric(dt_synth$bmi)
# dt_synth$age <- as.numeric(dt_synth$age)
# TODO Show some stats of new dataset
# TODO recheck correlations, maybe w/ function to plot both side-by-side
# TODO add models/predictions
Logit
Logit <- glm(stroke~., data=train, family = binomial(link = "logit"))
summary(Logit)
lr_prob1 <- predict(Logit, newdata = test, type="response")
lr_preds_test <- c(0,0,0,0,0,0,0,0,0,0,0)
i<-1
for (thresh in seq(0.25,0.75,0.05)){
lr_pred <- ifelse(lr_prob1 > thresh,1,0)
cm <- table(
as.factor(lr_pred),
as.factor(test$stroke)
)[2:1, 2:1]
lr_preds_test[i] <- F_meas(cm)
i<-i+1
}
