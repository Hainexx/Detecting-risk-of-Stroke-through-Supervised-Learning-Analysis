---
title: "Detecting risk of Stroke through Supervised Learning Analysis"
author: "Group 11: Ordinary Leading Students"
date: "6/02/2021"
output:
  pdf_document: default
  html_document: default
  word_document: default
header-includes:
- \usepackage{subfig}
- \usepackage{bbm}
urlcolor: blue
---

```{r, include=FALSE, message=FALSE,echo=FALSE}

# Load libraries
library(ggplot2)        # Basic plots
library(gridExtra)      # Multiple plot same figure
library(dplyr)          # Play w/ dataframes
library(broom)          # tidy()
library(GoodmanKruskal) # nice Corr Matrix
library(Hmisc)          # compute rcorr between quantitative vars
library(corrplot)       # plot nice corr matrix
library(caret)          # trainControl (train tree predictor)
library(pROC)
library(car)
library(randomForest)
#library(performanceEstimation)

###################################################################
# SMOTE stuff
library(ROCR)

remotes::install_github("dongyuanwu/RSBID")
library(RSBID) #cmd above to install it
###################################################################

# Set the current directory as working directory and load custom functions.
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
source("../utils/plots.R")
source("../utils/data_analysis.R")

```


\begin{abstract}
In the following paper we will present a statistical analysis of stroke related data. Our goal will be to predict whether a patient is likely to get a stroke based on multiple input parameters like gender, age, various diseases, and smoking status.
Each row in the data provides relevant information about the patient.

After some data cleaning, we plotted some interesting variables of our dataset to get some insight on
the content and structure of our data.
We then proceeded to the analysis. 


\end{abstract}

\section{Data}

We will now load and present our dataset (that can be retrieved at the following [link](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset)). \

\begin{enumerate}
\item id: unique identifier
\item gender: [Male, Female, Other]
\item age: age of the patient
\item hypertension = $\begin{cases} 1 \quad \text{if the patient has hypertension}\\  0 \quad \text{otherwise} \end{cases}$
\item heart\_disease = $\begin{cases} 1 \quad \text{if the patient has a heart disease}\\  0 \quad \text{otherwise} \end{cases}$
\item ever\_married = [Yes, No]
\item work\_type = [children, Govt\_jov, Never\_worked, Private, Self-employed]
\item Residence\_type = [Rural, Urban]
\item avg\_glucose\_level: average glucose level in blood
\item bmi: body mass index
\item smoking\_status = [formerly smoked, never smoked, smokes, Unknown\footnote{The information is unavailable for this patient}]
\item stroke = $\begin{cases} 1 \quad \text{if the patient had a stroke}\\  0 \quad \text{otherwise} \end{cases}$
\end{enumerate}
\newpage
```{r echo=FALSE}
# Load and summarize dataset
dataset = read.csv("stroke.csv")
str(dataset)
```


\section{Data Cleaning}

We convert our variables to the right data type and we show the updated summary.\

```{r, warning=FALSE,echo=FALSE}
# Remove id column (useless)
dataset$id = NULL

# Convert qualitative variables in factors
dataset$gender          = factor(dataset$gender)
dataset$hypertension    = factor(dataset$hypertension, levels = c(0,1), labels = c("No", "Yes"))
dataset$heart_disease   = factor(dataset$heart_disease, levels = c(0,1), labels = c("No", "Yes"))
dataset$ever_married    = factor(dataset$ever_married)
dataset$work_type       = factor(dataset$work_type)
dataset$residence_type  = factor(dataset$Residence_type)
dataset$smoking_status  = factor(dataset$smoking_status)
dataset$stroke          = factor(dataset$stroke, levels = c(0,1), labels = c("No", "Yes"))

# Convert quantitative variable in numeric
dataset$bmi             = as.numeric(dataset$bmi)

# Remove duplicate column (due to uppercase)
dataset$Residence_type  = NULL 

# Show dataset summary
str(dataset)

```
\section{ Data Visualization}

We can use different boxplots to visualize possible relations between our quantitative variables (**age**, **bmi** and **average glucose level**) and stroke status.\

```{r, warning=FALSE, fig.width=10, echo=FALSE}
grid.arrange(ggplot(dataset, aes(x=stroke ,y=age)) +
              geom_boxplot(fill= "#FDE725FF", alpha= 0.7), 
            ggplot(dataset, aes(x=stroke, y=bmi))+
              geom_boxplot(fill= "#2D708EFF", alpha= 0.7), 
            ggplot(dataset, aes(x=stroke, y=avg_glucose_level))+
              geom_boxplot(fill= "#440154FF", alpha= 0.7), 
            ncol=3)
```

From the plots above we can infer the following:
\begin{itemize}
\item \textbf{Age}: older people are more likely to have a stroke.
\item \textbf{Bmi}: there is no evident relation between stroke and bmi.
\item \textbf{Average glucose level}: the higher the level of glucose, the higher the relation with stroke
\end{itemize}

\newpage

Below we plot a few matrices to visualize possible relations between our qualitative variables and stroke status.\

```{r, warning=FALSE, fig.width=10, fig.height=7, fig.align='center', echo=FALSE}
grid.arrange(factors_plot(tidy(table(dataset %>% dplyr::select(stroke,work_type))), palette='Blues',
                         font_count_size=4, font_normalized_size=5.1, font_percentages_size=2.5,
                         font_categories_size=10), 
            factors_plot(tidy(table(dataset %>% dplyr::select(stroke,smoking_status))), palette='Greens',
                         font_count_size=4, font_normalized_size=5.1, font_percentages_size=2.5,
                         font_categories_size=10),
            factors_plot(tidy(table(dataset %>% dplyr::select(stroke,gender))), palette='Purples',
                         font_count_size=4, font_normalized_size=5.1, font_percentages_size=2.5,
                         font_categories_size=10),
            ncol=3, nrow=1)
```
```{r, warning=FALSE, fig.width=10, fig.height=5, fig.align='center', echo=FALSE}
grid.arrange(factors_plot(tidy(table(dataset %>% dplyr::select(stroke,hypertension))), palette='Greens',
                         font_count_size=3.5, font_normalized_size=5, font_percentages_size=2.5,
                         font_categories_size=10), 
            factors_plot(tidy(table(dataset %>% dplyr::select(stroke,heart_disease))), palette='Blues',
                         font_count_size=3.5, font_normalized_size=5, font_percentages_size=2.5,
                         font_categories_size=10), 
            factors_plot(tidy(table(dataset %>% dplyr::select(stroke,residence_type))), palette='Purples',
                         font_count_size=3.5, font_normalized_size=5, font_percentages_size=2.5,
                         font_categories_size=10),
            factors_plot(tidy(table(dataset %>% dplyr::select(stroke,ever_married))), palette='Oranges',
                         font_count_size=3.5, font_normalized_size=5, font_percentages_size=2.5,
                         font_categories_size=10),
            ncol=2, nrow=2)

```
\newpage
From these comparison matrices we can deduce the following:
\begin{itemize}
\item A lot of our subjects work in the private sector (57.24\%) and do not smoke (37\%), we can also notice a high predominance of subjects without hypertension (90.25\%) and heart diseases (94.6\%). These data should not worry us because they do not indicate unbalance in our dataset but just reflects the actual distribution of global population\footnote{Further information on this subject can be found at the following links: \begin{itemize}
                        \item \href{https://www.economicshelp.org/blog/2634/economics/private-sector-vs-public-sector/}{Work type}
                        \item \href{https://ourworldindata.org/smoking}{Smoking status}
                        \item \href{https://www.medscape.com/answers/241381-7614/what-is-the-global-prevalence-of-hypertension-high-blood-pressure}{Hypertension}
                        \item \href{https://pubmed.ncbi.nlm.nih.gov/32742886/}{Heart diseases}
                       \end{itemize}}.
\item We miss a lot of information on the smoking status of our participants (30.2\% unknown), this could evolve in a modeling problem if we do not address it properly.
\item A lot of our subjects have not suffered a stroke (95.1\%), this could cause us some problems but we will address it using the SMOTE technique.
\end{itemize}

Now we can finally show **qualitative** and **quantitative** correlations.

```{r, warning=FALSE, fig.align='center', echo=FALSE}
qualitative_vars = c('gender', 'hypertension', 'heart_disease', 'ever_married',
                      'work_type', 'smoking_status', 'residence_type')
plot(GKtauDataframe(dataset %>% dplyr::select(all_of(qualitative_vars))))
```
```{r, fig.height=4, fig.width=5, fig.align='center', echo=FALSE}

quantitative_vars = c('age', 'avg_glucose_level', 'bmi')
corr <- rcorr(as.matrix(dataset %>% dplyr::select(all_of(quantitative_vars))))
corrplot(corr$r, type = "upper", tl.col = "black", tl.srt = 45)
``` 

From the results above we are lead to believe that there is no multicollinearity in our instrumental variables. We will provide more evidence for this later, when we perform the regression. 

The only two correlations that stand out are the one between work_type and ever_married and the one between age and bmi, as expected. These two correlations are understandable given the nature of the data. 
Let us inspect this even further with some plots.


\newpage

```{r, echo=FALSE, warning=FALSE, message=FALSE,echo=FALSE}
factors_plot(tidy(table(dataset %>% dplyr::select(ever_married,work_type))), palette='Blues',
                         font_count_size=4, font_normalized_size=5.1, font_percentages_size=2.5,
                         font_categories_size=10)
```


This plot shows why there is correlation between the variables work_type and ever_married: the levels Never_worked and children in the work_type variable both have 0% of observations who have ever been married. This is unserstandable since children can't be married and people who have never worked are young are really likely to have never been married.


```{r, include=FALSE, message=FALSE,echo=FALSE}
#finding the intercept to use in the next plot
fit <- lm(bmi~age, data=dataset)
fit
```

```{r, echo=FALSE, warning=FALSE, message=TRUE}
plot(x=dataset$age, y=dataset$bmi) +
lines(0:100, c(0:100)*0.2+23, col='red')
```

With this plot a slight correlation between the variables bmi and age is noticeable.
However, this correlation is not strong enough to influence our model later on.


\section{Data Manipulation}

In order to facilitate our work, we removed the level **other** from the variable gender and the level **never_worked** from the variable work_type, since they are not relevant for the analysis.\

\textbf{SHOULD WE REMOVE UNKNNOWN SMOKING STATUS???}
```{r echo=FALSE}
# Remove rows
dataset = dataset %>%
          filter(gender != 'Other') %>%
          filter(work_type != 'Never_worked')

# Remove related levels
dataset = droplevels(dataset)
```

\subsection{NA Values}

We now look for NA values in our dataset:

```{r echo=FALSE}
# Check for NA in all columns
for (col_name in colnames(dataset)){
   if (anyNA(dataset[[col_name]]))
    print(paste(col_name, '-> ', sum(is.na(dataset[[col_name]])), ' NA'))
}
```

We notice that we have 201 NA just in the **bmi** variable. In order to avoid losing these rows, given that we already have a small dataset, we will predict their values using a fitted tree.\

```{r, warning=FALSE, message=FALSE,echo=FALSE}

# Define test set as set with missing data
missing_index <- which(is.na(dataset$bmi))

test_set <- dataset[missing_index,]
train_set <- dataset[-c(missing_index),]

# Fit the tree
tree = caret::train(bmi ~ ., 
                    data=train_set, 
                    method="rpart", 
                    trControl = trainControl(method = "cv"))

# Replace missing data with predicted data
bmi_pred <- predict(tree, newdata = test_set)
dataset[missing_index, 'bmi'] <- bmi_pred

# clean global environment
rm(test_set, train_set, tree, bmi_pred, missing_index)
```


\section{Statistical Model}

We will now begin splitting our dataset in train/test.\

```{r echo=FALSE}
# Set a fixed seed in order to have reproducible results
set.seed(42)

# 60-40 split
split_train_test <- createDataPartition(y = dataset$stroke, p=0.6, list = F)
train <- dataset[split_train_test,]
test <-  dataset[-split_train_test,]

print(table(train$stroke))
print(table(test$stroke))
```

\subsection{SMOTE algorithm}

Since our dataset has a problem of under sampling, we will use the \href{https://arxiv.org/pdf/1106.1813.pdf}{SMOTE} algorithm to create synthetic new data.\
```{r, warning=FALSE, message=FALSE,echo=FALSE}
# New smote algorithm
train_smoted <- SMOTE_NC(train, "stroke", k = 2, perc_maj = 50)

# Now we have a balanced dataset
table(train_smoted$stroke)
```
Notice that the SMOTE algorithm was only applied to the train set, this is done on pourpose to avoid the evaluation of our final model on synthetic data.\

\subsection{Logistic Regression}

We perform a logistic regression using  \textbf{stroke} as the dependent variable and the rest of the data as independent variables in order to see if we find some significant relationships.

```{r echo=FALSE}
Logit <- glm(stroke~., data=train_smoted, family = binomial(link = "logit"))
summary(Logit)
vif(Logit)
```

The only significant variables are **age**, **hypertension** and **average glucose level**, 
which have a positive impact on the increase of the logit probability.

Now we can also state with certainty that there is no multicollinearity in our data, due to the results
of the variance inflation factor test. In fact, all the values of the VIF are very close to 1, which 
indicates an almost total absence of multicollineairty.

**ADDRESS UNKNOWN SMOKING STATUS PROBLEM**

\subsection{Confusion Matrix and Statistics}

We will now evaluate our model over the test set.


```{r echo=FALSE}
library(caret)
lr_prob1 <- predict(Logit, newdata = test, type = "response")
lr_pred1 <- ifelse(lr_prob1 > 0.65,"Yes","No")

tb <- table(Predicted = lr_pred1, Actual = test$stroke)[2:1, 2:1]
tb
print(paste0("Accuracy: ", (tb[1:1,1:1] + tb[2:2, 2:2])/(tb[1:1,2:2] + tb[2:2, 1:1] + tb[1:1,1:1] + tb[2:2, 2:2])))
print(paste0("F1: ", F_meas(tb)))
print(paste0("Recall: ", recall(tb))) 
print(paste0("Precision: ", precision(tb))) 
```
```{r, warning=FALSE, message=FALSE, echo=FALSE}
test_roc <- roc(as.numeric(test$stroke)~lr_prob1 , plot = TRUE, print.auc = TRUE,percent=TRUE, ci=TRUE)
```
```{r, warning=FALSE, message=FALSE,echo=FALSE}
print(test_roc$auc)
```
As we can see from the outputs above, our model does not perform very well. 
With a threshold over 0.1 it predicts correctly just 62.6\% of the positive results (in our case, people who suffered a stroke), at the expense of 16\% of false positives.
Because this is such a sensitive subject, we would definitely prefer having more false positives than false negatives, but lowering our threshold, say to 0.05, increase our sensitivity to 81.8\%, but it lowers the specificity to 71.7\% (from 83.7\%).

The problem of this underperforming model could be addressed in two different ways:
\begin{enumerate}
\item We could speak with the stakeholders to understand how to best tune our threshold. In a real-world scenario this would translate into a discussion regarding the number of people we can take care of, even if they are false positives, in order to avoid rejecting people who actually need our help.
\item We could try and increase the accuracy of our model, and we will do that below using a Boosting technique.
\end{enumerate}

\section{Boosting}

Boosting is a technique used that convert weak learners to strong ones, and it works by iteratively learning weak classifiers with respect to a distribution and adding them to a final strong classifier.
Notice that, when they are added to the model, all the learners are weighted with relation to their prediction accuracy.

```{r echo=FALSE}
gbmGrid <- expand.grid(nIter=c(88,102,112,120,135))


trctrl <- trainControl(method = "cv"
                       , number = 10
                       #, repeats = 10
                       #, search = "random"
                       , classProbs = T
                       , summaryFunction = twoClassSummary
                       )

logit_fit <- train(stroke ~., data = train_smoted, method = "LogitBoost", trControl=trctrl,
                   tuneGrid=gbmGrid, 
                   metric= "ROC"
                   )
logit_fit

```

We can notice in the output above that boosting our model slightly improves its accuracy (AUC from 85\% to 86.6\%) when 102 iterations are computed.

```{r, echo=FALSE}
plot(logit_fit)
```
```{r predicting boost, echo=FALSE}

pred <- round(predict(logit_fit, newdata = test, type = "prob"),3)


pred <- as.factor(ifelse(pred[2] > 0.5,'Yes','No'))
tb <- table(Predicted = pred, Actual = test$stroke)[2:1, 2:1]
tb

print(paste0('Accuracy:', round((tb[1:1,1:1] + tb[2:2, 2:2])/(tb[1:1,2:2] + tb[2:2, 1:1] + tb[1:1,1:1] + tb[2:2, 2:2]),2)))
print(paste0("F1: ", round(F_meas(tb),2)))
print(paste0("Recall: ", round(recall(tb),2)))
print(paste0("Precision: ", round(precision(tb),2))) 

```
To try and achieve an even higher level of accuracy, we used a random forest.

```{r echo=FALSE, message=FALSE, warning=FALSE}

# Explore possibilities with more "BlackBox" alghorithms like Random Forest

# Random Forest -----------------------------
for (i in 1:11) {
  levels(train[,i]) <- make.names(c(levels(train[,i])))
}

for (i in 1:11) {
  levels(test[,i]) <- make.names(c(levels(test[,i])))
}


control <- trainControl(method='repeatedcv',
                        number=3,
                        repeats=5,
                        search = "grid",
                        #sampling = 'smote',
                        allowParallel=T
                        )

# Metric compare model is Accuracy
metric <- "Accuracy"

#Number randomely variable selected is mtry
mtry <- sqrt(ncol(train))

tunegrid <- expand.grid(.mtry=mtry+6)

# train the model
rfss <- caret::train(stroke~.,
                     data=train_smoted,
                     method='rf',
                     metric= metric,
                     tuneGrid=tunegrid,
                     trControl=control
                     )

#saveRDS(rf, "rf_model.rds")

rf <- readRDS("rf_model.rds")

print(rf)
model_rf <- predict(rf, newdata = test)


tb <- table(Predicted = model_rf, Actual = test$stroke)[2:1, 2:1]
tb

```
```{r echo=FALSE, message=FALSE, warning=FALSE}
print(paste0('Accuracy:', round((tb[1:1,1:1] + tb[2:2, 2:2])/(tb[1:1,2:2] + tb[2:2, 1:1] + tb[1:1,1:1] + tb[2:2, 2:2]),2)))
print(paste0("F1: ", round(F_meas(tb),2)))
print(paste0("Recall: ", round(recall(tb),2)))
print(paste0("Precision: ", round(precision(tb),2))) 
```
```{r echo=FALSE, message=FALSE, warning=FALSE}
plot(varImp(rf))
```

\newpage



\section{Conclusion}

In conclusion, we were able to construct a model that is able to predict with an 86% level of accuracy if an individual is more likely to suffer from a stroke than others based on his clinical records.
To be more precise, we can state that:
\begin{itemize}
\item \textbf{Age}: a one unit increase in age is associated with an increase in the log odds of having  a stroke by 0.07 units
\item \textbf{Hypertension}: a one unit increase in hypertension is associated with an increase in the log odds of having  a stroke by 0.45 units
\item \textbf{Average Glucose Level}: a one unit increase in average glucose level is associated with an increase in the log odds of having  a stroke by 0.003 units
\end{itemize}




